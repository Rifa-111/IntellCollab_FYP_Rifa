{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3129139072847682\n",
      "Precision: 0.17448031130552707\n",
      "F1 Score: 0.2139855222940043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' import pandas as pd\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score\\nfrom pymongo import MongoClient\\nimport numpy as np\\n\\n# Connect to MongoDB\\nclient = MongoClient(\\'mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/\\')\\ndb = client[\\'MyDatabase\\']\\ncollection = db[\\'Faculty_Project\\']\\n\\n# Load data from MongoDB into DataFrame\\ncursor = collection.find()\\ndf = pd.DataFrame(cursor)\\n\\n# Handle missing values by filling NaNs with empty strings\\ndf.fillna(\\'\\', inplace=True)\\n\\n# Preprocess the data\\n# Add your preprocessing steps here\\n\\n# Split data into features (X) and target variable (y)\\nX = df[[\\'Project_Description\\', \\'Skills\\']]\\ny = df[\\'Industry_Project_Name\\']\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Content-Based Filtering\\ntfidf_vectorizer = TfidfVectorizer(stop_words=\\'english\\')\\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train[\\'Project_Description\\'] + \\' \\' + X_train[\\'Skills\\'])\\n\\n# Train logistic regression model\\nmodel = LogisticRegression()\\nmodel.fit(X_train_tfidf, y_train)\\n\\n# Predict on test data\\nX_test_tfidf = tfidf_vectorizer.transform(X_test[\\'Project_Description\\'] + \\' \\' + X_test[\\'Skills\\'])\\ny_pred = model.predict(X_test_tfidf)\\n\\n# Calculate accuracy, precision, and F1 score\\naccuracy = accuracy_score(y_test, y_pred)\\nprecision = precision_score(y_test, y_pred, average=\\'micro\\')\\nf1 = f1_score(y_test, y_pred, average=\\'micro\\')\\n\\nprint(\"Accuracy:\", accuracy)\\nprint(\"Precision:\", precision)\\nprint(\"F1 Score:\", f1)\\n '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "# Add your preprocessing steps here\n",
    "\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['MyDatabase']\n",
    "collection = db['Faculty_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "# Add your preprocessing steps here\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3129139072847682\n",
      "Precision: 0.3129139072847682\n",
      "F1 Score: 0.3129139072847682\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "# For simplicity, we'll concatenate 'Project_Description' and 'Skills' columns as our text data\n",
    "df['text'] = df['Project_Description'] + ' ' + df['Skills']\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df['text']\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/rifa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/rifa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'recall_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     73\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m recall \u001b[38;5;241m=\u001b[39m \u001b[43mrecall_score\u001b[49m(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m\"\u001b[39m, precision)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recall_score' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    # Removing stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Stemming\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "    # Join tokens back into text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Project_Description'] = df['Project_Description'].apply(preprocess_text)\n",
    "df['Skills'] = df['Skills'].apply(preprocess_text)\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/rifa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/rifa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/var/folders/58/vdk28sms6qxgzmkckgchtb_h0000gn/T/ipykernel_11848/3018892253.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Skills'] = X['Skills'].str.split(',').apply(lambda x: ' '.join(x))  # Convert skills to separate features\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Connect to MongoDB and load data\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Project_Description'] = df['Project_Description'].apply(preprocess_text)\n",
    "df['Skills'] = df['Skills'].apply(preprocess_text)\n",
    "\n",
    "# Feature Engineering\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "X['Skills'] = X['Skills'].str.split(',').apply(lambda x: ' '.join(x))  # Convert skills to separate features\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization (Content-Based Filtering)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Project_Description'] + ' ' + X_train['Skills'])\n",
    "\n",
    "# Model Selection and Hyperparameter Tuning\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30]}\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-Validation\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Evaluate on Test Set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Project_Description'] + ' ' + X_test['Skills'])\n",
    "y_pred = best_rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://w1798587:Success%402024@cluster0.69rs1dl.mongodb.net/')\n",
    "db = client['IntellCollab']\n",
    "collection = db['User_Project']\n",
    "\n",
    "# Load data from MongoDB into DataFrame\n",
    "cursor = collection.find()\n",
    "df = pd.DataFrame(cursor)\n",
    "\n",
    "# Handle missing values by filling NaNs with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    # Removing stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Stemming\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "    # Join tokens back into text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Project_Description'] = df['Project_Description'].apply(preprocess_text)\n",
    "df['Skills'] = df['Skills'].apply(preprocess_text)\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df[['Project_Description', 'Skills']]\n",
    "y = df['Industry_Project_Name']\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X['Project_Description'] + ' ' + X['Skills'])\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = cv_scores.mean()\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Cross-Validation Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    " '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
